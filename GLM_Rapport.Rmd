---
title: "GLM - Data challenge Epismoke 2.1"
author: "Garance Malnoë, Matthias Mazet, Léonie Breuzat"
date: "18 décembre 2024"
output: html_document
---

Ce datachallenge consiste à prédire le statut tabagique d'individu : actuellement fumeur (current), ancien fumer (former) ou n'ayant jamais fumé (never). Pour cela, nous allons étudier trois méthodes différentes que nous entrainerons sur le jeu de données `data_train` et que nous testerons sur le jeu de données `data_test`. 
```{r}
data_train = readRDS(file = "data_train.rds") # Données de train 
data_test = readRDS(file = "data_test.rds") # Données de test
dim(data_train)
dim(data_test)
head(data_train[,1:6])
```
Les deux jeux de données `data_train` et `data_test`, sont composés de  421 et 200 individus respectivement et de 10004 variables :

- smoking_status : variable qualitative (current, former, never) que l'on cherche à prédire.

- never/former/current01 : la transformation en variables binaires de la variable smoking_status qui va nous permettre de construire les modèles.

- cg######## : variables quantitatives (sondes) représentant le taux de méthylation de différents gènes qui seront les variables explicatives.

# Prétraitement

On commence par un pré-traitement qui sera commun aux trois modèles.

On récupère le noms des colonnes correspondants aux sondes (variables exmplicatives).
```{r}
#Nom des sondes
probes = colnames(data_train)[5:10004] 
head(data_train[,probes[1:10]])
```
On trace la densité des 
```{r}
# Description statistique : la densité 
plot(density(as.matrix(data_train[,probes])),main="Densité des valeurs prises par les sondes", xlab="Densité",ylab="Valeurs prises par les variables (methylation)")
```

Sur le graphique, nous pouvons voir apparaitre deux pics : un premier dans l'intervalle $[0;0.2]$ (absence de méthylation) et un second dans l'intervalle $[0;0.7]$ (présence de methylation). 

Regardons la distribution des statuts tabagiques
```{r}
table(data_train$smoking_status)
prop.table(table(data_train$smoking_status))
```
Les 3 statuts sont présents de manière presque équidistribuées. Si on choisissait le modèle nul renvoyant dans tous les cas "former" (le statut le plus courant), on pourrait s'attendre à environ 60% d'erreur.

Pour entrainer nos modèles et pouvoir les tester notamment pour faire de l'hyperparamétrage, nous allons séparer le jeu de donénes `data_train` en deux parties : une partie pour l'entrainement `data_train1` (75%) et une partie pour le test `data_train2` (25%).
```{r}
set.seed(1) # Pour avoir des résultats aléatoire reproductibles.

data_train1 = data_train[sample(1:nrow(data_train), round(nrow(data_train)*.75))
                         ,]
data_train2 = data_train[setdiff(rownames(data_train), rownames(data_train1)),]
```

```{r}
# Comparaison de la séparation de data_train
prop.table(table(data_train1$smoking_status)) 
prop.table(table(data_train2$smoking_status))
```
On remarque que les proportions de chaque groupe (chaque statut tabagique) ne sont pas exactement les mêmes entre data_train1 et data_train2.

Pour les trois modèles, nous n'allons pas utiliser toutes les sondes pour construire nos modèles pour éviter le surajustement et parce que tout simplement certaines sondes n'apportent pas ou peu d'informations. Pour sélectionner les sondes, nous allons construire les modèles linéaires de la forme `lm(sonde~smoking_status)` pour chaque sonde. Cela nous permettra d'étudier la significativité du lien entre le statut tabagique et chaque sonde  à partir de la p-valeur associée au coefficent directeur et ainsi de classer les sondes. 
```{r}
siscreening = function(data_train) {
  probes = colnames(data_train)[5:length(data_train)]  # Noms des sondes
  pval_fisher = c()
  r2 = c()
  for (p in probes) {
    #On crée un modèle linéaire sonde~smoking_status
    m = lm(data_train[,p]~data_train[,"smoking_status"])  
    # On récupère la p-valeur du modèle
    pval_fisher = c(pval_fisher, anova(m)[1,5])  
    # On récupère le r2 associé à ce modèle
    r2 = c(r2, summary(m)$r.squared) 
  }
  names(pval_fisher)  = probes
  names(r2)           = probes
  return(data.frame(pval_fisher=pval_fisher, r2=r2)) 
}
# On mémoise la fonciton pour mettre le résultat en cache.
if (!exists("msiscreening")) {msiscreening = memoise::memoise(siscreening)} 
sis_res = msiscreening(data_train1) # Dataframe résutlat
```

```{r}
# Graphe R2 et p-value
plot(sis_res$r2, -log10(sis_res$pval),
     main="-log10(p-value) des modèles linéaire à une sonde en fonction du R2",
     xlab="R²",ylab="-log10(p-value)")
```
On observe une relation logarithmique entre la p-valeur et le R² : quand la p-valeur devient très petite (-log10(p_val) grand), le R² augmente.

On tri les sondes par ordre croissant de p-valeur.
```{r}
# Tri des sondes en fonction de la p-value
sis_probes = rownames(sis_res)[order(sis_res$pval_fisher)]
head(sis_res[sis_probes,])
# Commentaire : ils ont tous un R2 proche de 0.1, c'est mieux que rien mais c'est pas top.
```

# Méthodes étudiées
Nous allons étudier trois méthodes différentes pour ce datachallenge : un arbre de décision construit à partir de modèles linéaire, un algorithme de random forest et un alorithme de XGBoost. Nous détaillons chacun de ces méthodes dans les parties suivantes.

## 1. Arbre de décision à partir de modèles linéaires
### Idée
L'idée de ce modèle est de construire tout d'abord un premier modèle permettant de séparer les individus en deux groupes selon un des trois statuts tabagiques puis de construire un second modèle entrainé uniquement sur les données des individus des deux autres statuts pour à nouveau séparer les individus restants dans deux groupe selon un des deux status tabagiques restants. Puis, finalement, combiner ces deux modèles pour n'en former qu'un seul : un arbre de décision.

Voici un exemple :
![This is an image](image_arbre_decision.jpg)

### Premier modèle
Nous allons construire pour les trois statuts tabagiques (never, current et former) le premier modèle ayant pour but de prédire si un individu est du statut considéré ou non. Pour chacun de ces modèles, nous allons également réaliser une études des meilleurs hyperparamètres (nombres de sondes et seuil de décision) pour obtenir le meilleur modèle possible. Finalement, nous comparerons les trois modèles sur leur précision (proportion de prédiction correctes).

Commençons avec le statut current, on utilise la variable binaire `current01`, pour construire le modèle.
```{r}
# Fonciton pour créer un modèle linéaire avec les i meilleures sondes
model_current_sis_i = function(data_train, i, screening_func=msiscreening){
  formula = as.formula(paste0(c("current01~1", sis_probes[0:i]), collapse="+")) ; 
  m = glm(formula, data_train, family=binomial(link="logit"))
  return(m)
}

# On regarde le sur apprentissage sur les 50 sondes
iap1 = c()
iap2 = c()
for (i in 0:50) {
  m = model_current_sis_i(data_train1, i)
  pred_train1 = predict.glm(m, data_train1, type="response")
  pred_train2 = predict.glm(m, data_train2, type="response")
  iap1 = c(iap1, sum(ifelse(pred_train1>0.5, 1, 0) != data_train1$current01) / nrow(data_train1))
  iap2 = c(iap2, sum(ifelse(pred_train2>0.5, 1, 0) != data_train2$current01) / nrow(data_train2))
}
plot(iap1, col=4, pch=16, cex=1, main="Incorrect Answers Proportion en fonction du nombre de sondes sur les deux jeux de données",xlab="Nombre de sondes",ylab="Incorrect Answers Proportion",cex.main=0.8)
points(iap2, col=2, pch=16, cex=1)
legend("bottomright", c("iap1", "iap2"), col=c(4,2), pch=16, cex=0.8)
i=8
abline(v=i, col=2)
```

On voit sur la figure précédente qu'en prenant plus de 8 sondes l'erreur diminue sur le jeu de données `data_train1` mais qu'il augmente sur le jeu de données `data_train2` : il y a du sur-apprentissage. Certaines sondes sont corélées et n'apporte rien. Pour sélectionner les meilleures sondes, nous allons utiliser la fonction step qui sélectionne les sondes à partir du critère d'Aikaike (AIC)

```{r}
# Fonction de création de modèles step pour CURRENT
stepforward_current = function(data_train, sis_probes, nb_sis_probes=200, trace=0, k=2) {
  m_lo = glm(current01 ~ 1, data=data_train[,c("current01", sis_probes[1:nb_sis_probes])])
  m_sup = glm(current01 ~ ., data=data_train[,c("current01", sis_probes[1:nb_sis_probes])])
  m_fwd = step(m_lo, method="forward", scope=list(upper=m_sup,lower=m_lo), trace=trace, k=k)
  return(m_fwd)
}
```

Testons les résultats sur `data_train2` avec le modèle step obtenu à partir des 90 premières sondes.
```{r}
# Exemple Modèle step obtenu à partir des 90 meilleurs sondes.
step_model_current_90 = stepforward_current(data_train1, sis_probes, nb_sis_probes = 90,trace=0)

# Test de l'accuracy sur le step_model_current_90
predicted_probs <- predict(step_model_current_90, newdata = data_train2, type = "response")
predicted_classes <- ifelse(predicted_probs > 0.5, 1, 0) # On pose le seuil à 0.5
confusion_matrix <- table(Predicted = predicted_classes, Actual = data_train2$current01)
print(confusion_matrix)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(paste("Précision:", accuracy))
```
Les résultats sont plutôt bons, on a une précision de 80,9% mais ce résultat est sans doute améliorable. En effet, on peut jouer sur deux hyperparamètres : le nombre de sondes utilisées pour former le modèle avec step et le seuil de décision (le modèle prédit une valeur nuémrique, on avait choisit arbitrairement que si la valeur était supérieur à 0.5 alors l'individu appartenait à la classe current).

Pour faire cela, on va tout d'abord définir une fonction générale de prédiction qui prend en argument des données dont on veut prédire la classe, un modèle (pour faire varier le nombre de sonde) et un seuil.

```{r}
# Fonction générale de prédiction à partir d'un modèle step + seuil de décision
predict_current <- function(data,step_model, seuil){
  predicted_probs <- predict(step_model, newdata = data, type = "response")
  predicted_classes <- ifelse(predicted_probs > seuil, 1, 0)
  return(predicted_classes)
}
```

En suite, on crée les modèles pour les différents nombres de sondes. On choisir de prendre 50 à 200 sondes par pas de 10. Cela fait 16 possibilités.
```{r}

# Modèles pour différents nombres de sondes 50 à 200 avec un pas de 10.
create_modeles_current <- function(from = 50, to = 200, by = 10) {
  res <- list()
  for (i in seq(from = from, to = to, by = by)) {
    res[[length(res) + 1]] <- stepforward_current(data_train1, sis_probes, nb_sis_probes = i, trace = 0)
  }
  return(res)
}
modeles_current <- create_modeles_current()
```

On crée une fonction pour automatiser l'hyperparamétrage, elle va tester toutes les combinaison de modèles et de seuil et renvoyer la meilleur précision obtenue sur `data_train2` et les modalités associées.
```{r}
# Fonction pour l'hyper-paramétrage de CURRENT
hyperparametrage_current<- function(data, list_modeles_current, list_seuil_current){
  best_accuracy <- 0
  best_seuil_current <- 0
  best_num_model_current <- 1
  
  
  nb <- length(list_modeles_current)*length(list_seuil_current)
  i <- 0
  
  num_model_current <- 0
  for(step_model_current in list_modeles_current){
    num_model_current <- num_model_current +1
    for(seuil_current in list_seuil_current){
      i <- i+1
      if(i%%100 == 0){
        print(paste0(i,"/",nb))
      }
      confusion_matrix <- table(Predicted = predict_current(data,step_model_current,seuil_current), Actual = data$current01)
      accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
      if(accuracy > best_accuracy){
            best_accuracy <- accuracy
            best_num_model_current <- num_model_current
            best_seuil_current <- seuil_current
      }
    }
  }
  return(c(best_accuracy,best_num_model_current,best_seuil_current))
}

liste_seuils <- seq(from=0, to=1, by= 0.025)
hyperparametrage_current(data_train2,modeles_current,liste_seuils)
```
Les meilleurs hyperparamètres sont donc 190 sondes avec un seuil de 0.575 qui donne une précision de 0.829.

On réitère le même processus avec le statut never.

Modèles sis avec les i meilleures sondes
```{r}
# NEVER
model_never_sis_i = function(data_train, i, screening_func=msiscreening){
  sis_res = screening_func(data_train)  
  sis_probes = rownames(sis_res)[order(sis_res$pval_fisher)]
  formula = as.formula(paste0(c("never01~1", sis_probes[0:i]), collapse="+")) ; 
  m = glm(formula, data_train, family=binomial(link="logit"))
  return(m)
}

# On regarde le sur apprentissage sur les 50 sondes
iap1 = c()
iap2 = c()
for (i in 0:50) {
  m = model_never_sis_i(data_train1, i)
  pred_train1 = predict.glm(m, data_train1, type="response")
  pred_train2 = predict.glm(m, data_train2, type="response")
  iap1 = c(iap1, sum(ifelse(pred_train1>0.5, 1, 0) != data_train1$never01) / nrow(data_train1))
  iap2 = c(iap2, sum(ifelse(pred_train2>0.5, 1, 0) != data_train2$never01) / nrow(data_train2))
}
plot(iap2, col=2, pch=16, cex=1,ylim=c(0.10,0.40),main="Incorrect Answers Proportion en fonction du nombre de sondes sur les deux jeux de données",xlab="Nombre de sondes",ylab="Incorrect Answers Proportion",cex.main=0.8)
points(iap1, col=4, pch=16, cex=1)
legend("bottomright", c("iap1", "iap2"), col=c(4,2), pch=16, cex=0.8)
i=10
abline(v=i, col=2)
```
Ici aussi, on voit qu'en prennant trop de sondes la proportion d'erreur augment sur les données de `data_train2`. A nouveau, on va utiliser la fonciton Step pour sélectionner les sondes.

Fonction step :
```{r}
stepforward_never = function(data_train, sis_probes, nb_sis_probes=200, trace=0, k=2) {
  m_lo = glm(never01 ~ 1, data=data_train[,c("never01", sis_probes[1:nb_sis_probes])])
  m_sup = glm(never01 ~ ., data=data_train[,c("never01", sis_probes[1:nb_sis_probes])])
  m_fwd = step(m_lo, method="forward", scope=list(upper=m_sup,lower=m_lo), trace=trace, k=k)
  # print(m_fwd$call)
  return(m_fwd)
}
```

Exemple avec 90 sondes et un seuil à 0.55 :
```{r}
# Exemple avec 90 sondes
step_model_never_90 = stepforward_never(data_train1, sis_probes, nb_sis_probes = 90,trace=0)

# On regarde les résultats sur data_train2
predicted_probs <- predict(step_model_never_90, newdata = data_train2, type = "response")
predicted_classes <- ifelse(predicted_probs > 0.55, 1, 0)
confusion_matrix <- table(Predicted = predicted_classes, Actual = data_train2$never01)
print(confusion_matrix)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(paste("Précision:", accuracy))
```
En prennant 90 sondes, on obtient une précision nettement plus faible pour never que pour current. Essayons de nouveau de trouver de meilleurs hyperparamètres (seuil et nombre de sondes).

On commence par coder la fonction générale de prédiciton qui prend en entrée les données dont il faut prédire la classe, le modèle à utiliser et le seuil.
```{r}
# Fonction générale
predict_never <- function(data,step_model, seuil){
  predicted_probs <- predict(step_model, newdata = data, type = "response")
  predicted_classes <- ifelse(predicted_probs > seuil, 1, 0)
  return(predicted_classes)
}
```

Modèles pour différents nombres de sondes, on va pendre 50 à 200 sondes avec un pas de 10.
```{r}
# On crée des modèles pour l'hyperparamétrage.
create_modeles_never <- function(from = 50, to = 200, by = 10) {
  res <- list()
  for (i in seq(from = from, to = to, by = by)) {
    res[[length(res) + 1]] <- stepforward_never(data_train1, sis_probes, nb_sis_probes = i, trace = 0)
  }
  return(res)
}
modeles_never <- create_modeles_never()
```

```{r}
# Fonction pour l'hyper-paramétrage de never
hyperparametrage_never<- function(data, list_modeles_never, list_seuil_never){
  best_accuracy <- 0
  best_seuil_never <- 0
  best_num_model_never <- 1
  
  nb <- length(list_modeles_never)*length(list_seuil_never)
  
  num_model_never <- 0
  for(step_model_never in list_modeles_never){
    num_model_never <- num_model_never +1
    for(seuil_never in list_seuil_never){
      confusion_matrix <- table(Predicted = predict_never(data,step_model_never,seuil_never), Actual = data$never01)
      accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
      if(accuracy > best_accuracy){
        best_accuracy <- accuracy
        best_num_model_never <- num_model_never
        best_seuil_never <- seuil_never
      }
    }
  }
  return(c(best_accuracy,best_num_model_never,best_seuil_never))
}

liste_seuils <- seq(from=0, to=1, by= 0.025)
hyperparametrage_never(data_train2,modeles_never,liste_seuils)
```
Pour never, les meilleurs hyperparamètres sont donc 70 sondes avec un seuil de 0.425 qui donne une précision de 0.724 : c'est moins bon que current.

Enfin, on essaye également avec le statut former.
```{r}
# FORMER
model_former_sis_i = function(data_train, i, screening_func=msiscreening){
  print(paste0("model sis ", i))
  sis_res = screening_func(data_train)  
  sis_probes = rownames(sis_res)[order(sis_res$pval_fisher)]
  formula = as.formula(paste0(c("former01~1", sis_probes[0:i]), collapse="+")) ; 
  m = glm(formula, data_train, family=binomial(link="logit"))
  return(m)
}
# On regarde le sur apprentissage sur les 50 sondes
iap1 = c()
iap2 = c()
for (i in 0:50) {
  m = model_former_sis_i(data_train1, i)
  pred_train1 = predict.glm(m, data_train1, type="response")
  pred_train2 = predict.glm(m, data_train2, type="response")
  iap1 = c(iap1, sum(ifelse(pred_train1>0.5, 1, 0) != data_train1$former01) / nrow(data_train1))
  iap2 = c(iap2, sum(ifelse(pred_train2>0.5, 1, 0) != data_train2$former01) / nrow(data_train2))
}
plot(iap1, col=4, pch=16, cex=1)
points(iap2, col=2, pch=16, cex=1)
legend("bottomright", c("iap1", "iap2"), col=c(4,2), pch=16, cex=0.8)
i=8
abline(v=i, col=2)

```

```{r}

# On effectue un step 
stepforward_former = function(data_train, sis_probes, nb_sis_probes=200, trace=0, k=2) {
  m_lo = glm(former01 ~ 1, data=data_train[,c("former01", sis_probes[1:nb_sis_probes])])
  m_sup = glm(former01 ~ ., data=data_train[,c("former01", sis_probes[1:nb_sis_probes])])
  m_fwd = step(m_lo, method="forward", scope=list(upper=m_sup,lower=m_lo), trace=trace, k=k)
  # print(m_fwd$call)
  return(m_fwd)
}
```

```{r}
step_model_former_90 = stepforward_former(data_train1, sis_probes, nb_sis_probes = 90,trace=0)

# On regarde les résultats sur data_train2
predicted_probs <- predict(step_model_former_90, newdata = data_train2, type = "response")
predicted_classes <- ifelse(predicted_probs > 0.55, 1, 0)
confusion_matrix <- table(Predicted = predicted_classes, Actual = data_train2$former01)
print(confusion_matrix)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(paste("Précision:", accuracy))
```

```{r}
# Fonction générale
predict_former <- function(data,step_model, seuil){
  predicted_probs <- predict(step_model, newdata = data, type = "response")
  predicted_classes <- ifelse(predicted_probs > seuil, 1, 0)
  return(predicted_classes)
}
```

```{r}
# On crée des modèles pour l'hyperparamétrage.
create_modeles_former <- function(from = 50, to = 200, by = 10) {
  res <- list()
  for (i in seq(from = from, to = to, by = by)) {
    print(paste0(i, "/", to))
    res[[length(res) + 1]] <- stepforward_former(data_train1, sis_probes, nb_sis_probes = i, trace = 0)
  }
  return(res)
}
modeles_former <- create_modeles_former()
```

```{r}
# Fonction pour l'hyper-paramétrage de former
hyperparametrage_former<- function(data, list_modeles_former, list_seuil_former){
  best_accuracy <- 0
  best_seuil_former <- 0
  best_num_model_former <- 1
  
  
  nb <- length(list_modeles_former)*length(list_seuil_former)
  i <- 0
  
  num_model_former <- 0
  for(step_model_former in list_modeles_former){
    num_model_former <- num_model_former +1
    for(seuil_former in list_seuil_former){
      i <- i+1
      if(i%%10 == 0){
        print(paste0(i,"/",nb))
      }
      confusion_matrix <- table(Predicted = predict_former(data,step_model_former,seuil_former), Actual = data$former01)
      accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
      if(accuracy > best_accuracy){
        best_accuracy <- accuracy
        best_num_model_former <- num_model_former
        best_seuil_former <- seuil_former
      }
    }
  }
  return(c(best_accuracy,best_num_model_former,best_seuil_former))
}

hyperparametrage_former(data_train2,modeles_former,list(0.4,0.425,0.45,0.475,0.5,0.525,0.55,0.575,0.6))

# Res : 
# Accuracy : 0.7142
# Modèle n*10 -> 140 sondes
# Seuil : 0.575
```

Comme le modèle Current est celui avec la meilleure précision, on va partir de ce statut comme première partie de l'arbre. Nous allons maintenant construire deux modèles (former et never) uniquement entrainé sur les données des individus n'étant pas actuellement current (puisqu'ils sont censés être labelisé current par le modèle current).

### Deuxième modèle
```{r}

# On va repartir de data_train1 et data_train2 mais en enlevant les gens qui sont current.
data_train1_notcurrent <- data_train1[data_train1$current01!=1,]
data_train2_notcurrent <- data_train2[data_train2$current01!=1,]
dim(data_train1)
dim(data_train1_notcurrent)
dim(data_train2)
dim(data_train2_notcurrent)
```

```{r}
# NOT CURRENT - NEVER
# NEVER
model_never_sis_i = function(data_train, i, screening_func=msiscreening){
  print(paste0("model sis ", i))
  sis_res = screening_func(data_train)
  sis_probes = rownames(sis_res)[order(sis_res$pval_fisher)]
  formula = as.formula(paste0(c("never01~1", sis_probes[0:i]), collapse="+")) ; 
  m = glm(formula, data_train, family=binomial(link="logit"))
  return(m)
}

# On effectue un step 
stepforward_never = function(data_train, sis_probes, nb_sis_probes=200, trace=0, k=2) {
  m_lo = glm(never01 ~ 1, data=data_train[,c("never01", sis_probes[1:nb_sis_probes])])
  m_sup = glm(never01 ~ ., data=data_train[,c("never01", sis_probes[1:nb_sis_probes])])
  m_fwd = step(m_lo, method="forward", scope=list(upper=m_sup,lower=m_lo), trace=trace, k=k)
  # print(m_fwd$call)
  return(m_fwd)
}

# Exemple avec 90 sondes
step_model_notcurrent_never_90 = stepforward_never(data_train1_notcurrent, sis_probes, nb_sis_probes = 90,trace=0)

# On regarde les résultats sur data_train2
predicted_probs <- predict(step_model_notcurrent_never_90, newdata = data_train2_notcurrent, type = "response")
predicted_classes <- ifelse(predicted_probs > 0.5, 1, 0)
confusion_matrix <- table(Predicted = predicted_classes, Actual = data_train2_notcurrent$never01)
print(confusion_matrix)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(paste("Accuracy:", accuracy))
# Accuracy : 0.5217

# Fonction générale
predict_notcurrent_never <- function(data,step_model, seuil){
  predicted_probs <- predict(step_model, newdata = data, type = "response")
  predicted_classes <- ifelse(predicted_probs > seuil, 1, 0)
  return(predicted_classes)
}

# On crée des modèles pour l'hyperparamétrage.
create_modeles_notcurrent_never <- function(from = 50, to = 200, by = 10) {
  res <- list()
  for (i in seq(from = from, to = to, by = by)) {
    print(paste0(i, "/", to))
    res[[length(res) + 1]] <- stepforward_never(data_train1_notcurrent, sis_probes, nb_sis_probes = i, trace = 0)
  }
  return(res)
}
modeles_notcurrent_never <- create_modeles_notcurrent_never()

# Fonction pour l'hyper-paramétrage de never
hyperparametrage_notcurrent_never<- function(data, list_modeles_never, list_seuil_never){
  best_accuracy <- 0
  best_seuil_never <- 0
  best_num_model_never <- 1
  
  
  nb <- length(list_modeles_never)*length(list_seuil_never)
  i <- 0
  
  num_model_never <- 0
  for(step_model_never in list_modeles_never){
    num_model_never <- num_model_never +1
    for(seuil_never in list_seuil_never){
      i <- i+1
      if(i%%10 == 0){
        print(paste0(i,"/",nb))
      }
      confusion_matrix <- table(Predicted = predict_never(data,step_model_never,seuil_never), Actual = data$never01)
      accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
      if(accuracy > best_accuracy){
        best_accuracy <- accuracy
        best_num_model_never <- num_model_never
        best_seuil_never <- seuil_never
      }
    }
  }
  return(c(best_accuracy,best_num_model_never,best_seuil_never))
}

hyperparametrage_notcurrent_never(data_train2_notcurrent,modeles_notcurrent_never,list(0.4,0.425,0.45,0.475,0.5,0.525,0.55,0.575,0.6))
# Res
# Accuracy : 0.5652
# Modèle n*3 -> 70 sondes
# Seuil : 0.425

```

```{r}
# NOT CURRENT - former
# former
model_former_sis_i = function(data_train, i, screening_func=msiscreening){
  print(paste0("model sis ", i))
  sis_res = screening_func(data_train)
  sis_probes = rownames(sis_res)[order(sis_res$pval_fisher)]
  formula = as.formula(paste0(c("former01~1", sis_probes[0:i]), collapse="+")) ; 
  m = glm(formula, data_train, family=binomial(link="logit"))
  return(m)
}

# On effectue un step 
stepforward_former = function(data_train, sis_probes, nb_sis_probes=200, trace=0, k=2) {
  m_lo = glm(former01 ~ 1, data=data_train[,c("former01", sis_probes[1:nb_sis_probes])])
  m_sup = glm(former01 ~ ., data=data_train[,c("former01", sis_probes[1:nb_sis_probes])])
  m_fwd = step(m_lo, method="forward", scope=list(upper=m_sup,lower=m_lo), trace=trace, k=k)
  # print(m_fwd$call)
  return(m_fwd)
}

# Exemple avec 90 sondes
step_model_notcurrent_former_90 = stepforward_former(data_train1_notcurrent, sis_probes, nb_sis_probes = 90,trace=0)

# On regarde les résultats sur data_train2
predicted_probs <- predict(step_model_notcurrent_former_90, newdata = data_train2_notcurrent, type = "response")
predicted_classes <- ifelse(predicted_probs > 0.5, 1, 0)
confusion_matrix <- table(Predicted = predicted_classes, Actual = data_train2_notcurrent$former01)
print(confusion_matrix)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(paste("Accuracy:", accuracy))
# Accuracy : 0.5217

# Fonction générale
predict_notcurrent_former <- function(data,step_model, seuil){
  predicted_probs <- predict(step_model, newdata = data, type = "response")
  predicted_classes <- ifelse(predicted_probs > seuil, 1, 0)
  return(predicted_classes)
}

# On crée des modèles pour l'hyperparamétrage.
create_modeles_notcurrent_former <- function(from = 50, to = 200, by = 10) {
  res <- list()
  for (i in seq(from = from, to = to, by = by)) {
    print(paste0(i, "/", to))
    res[[length(res) + 1]] <- stepforward_former(data_train1_notcurrent, sis_probes, nb_sis_probes = i, trace = 0)
  }
  return(res)
}
modeles_notcurrent_former <- create_modeles_notcurrent_former()

# Fonction pour l'hyper-paramétrage de former
hyperparametrage_notcurrent_former<- function(data, list_modeles_former, list_seuil_former){
  best_accuracy <- 0
  best_seuil_former <- 0
  best_num_model_former <- 1
  
  
  nb <- length(list_modeles_former)*length(list_seuil_former)
  i <- 0
  
  num_model_former <- 0
  for(step_model_former in list_modeles_former){
    num_model_former <- num_model_former +1
    for(seuil_former in list_seuil_former){
      i <- i+1
      if(i%%10 == 0){
        print(paste0(i,"/",nb))
      }
      confusion_matrix <- table(Predicted = predict_former(data,step_model_former,seuil_former), Actual = data$former01)
      accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
      if(accuracy > best_accuracy){
        best_accuracy <- accuracy
        best_num_model_former <- num_model_former
        best_seuil_former <- seuil_former
      }
    }
  }
  return(c(best_accuracy,best_num_model_former,best_seuil_former))
}

hyperparametrage_notcurrent_former(data_train2_notcurrent,modeles_notcurrent_former,list(0.4,0.425,0.45,0.475,0.5,0.525,0.55,0.575,0.6))
# Res
# Accuracy : 0.5652
# Modèle n*3 -> 70 sondes
# Seuil : 0.525
```
Les deux ont les mêmes résultats donc arbitrairement on choisi never

### Combinaison des deux modèles
```{r}
predict_current_never<- function(data,step_model_current,seuil_current,step_model_never,seuil_never){
  
  # Étape 1 : Initialisation du vecteur de prédictions
  n <- nrow(data)
  predictions <- rep(NA, times=n)
  
  # Étape 2 : Prédictions pour "current"
  is_current <- predict_current(data,step_model_current,seuil_current) == 1
  predictions[is_current] <- "current"
  
  # Étape 3 : Prédictions pour "never" parmi les non-classés
  remaining <- is.na(predictions)
  is_never <- predict_notcurrent_never(data[remaining, ],step_model_never,seuil_never) == 1
  predictions[which(remaining)[is_never]] <- "never"
  
  # Étape 4 : Tout le reste est "former"
  predictions[is.na(predictions)] <- "former"
  
  return(predictions)
}

model_current_final <- stepforward_current(data_train1, sis_probes, nb_sis_probes = 190,trace=0)

model_never_final <- stepforward_never(data_train1_notcurrent, sis_probes, nb_sis_probes = 70,trace=0)

```

```{r}
# Essai sur data_train2
predicted <- predict_current_never(data_train2, model_current_final,0.575,model_never_final,0.425)
confusion_matrix <- table(Predicted = predicted, Actual = data_train2$smoking_status)
print(confusion_matrix)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(paste("Accuracy:", accuracy))
```


## 2. Random forest

## 3. XGBoost

# Résultats

## 1. Arbre de décision à partir de modèles linéaires
### Résultats sur data_train2

### Résultats sur data_test
La soumission correspondante sur CodaBench est la numéro 481 du 15 décembre 2024 publiée par l'utilisateur malnoe.  Le résultat obtenu est de 0.46.

## 2. Random forest
### Résultats sur data_train2
### Résultats sur data_test
Mettre numéro de la soumission sur codabench.

## 3. XGBoost
### Résultats sur data_train2
### Résultats sur data_test
Mettre numéro de la soumission sur codabench.

# Discussion
## Commentaires des résultats
## Proposer des faits pour détailler les résultats (cohérence ou différences)

