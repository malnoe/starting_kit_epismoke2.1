---
title: "GLM - Data challenge Epismoke 2.1"
author: "Garance Malnoë, Matthias Mazet, Léonie Breuzat"
date: "18 décembre 2024"
output: html_document
---

Ce datachallenge consiste à prédire le statut tabagique d'individu : actuellement fumeur (current), ancien fumer (former) ou n'ayant jamais fumé (never). Pour cela, nous allons étudier trois méthodes différentes que nous entrainerons sur le jeu de données `data_train` et que nous testerons sur le jeu de données `data_test`. 
```{r}
data_train = readRDS(file = "data_train.rds") # Données de train 
data_test = readRDS(file = "data_test.rds") # Données de test
dim(data_train)
dim(data_test)
head(data_train[,1:6])
```
Les deux jeux de données `data_train` et `data_test`, sont composés de  421 et 200 individus respectivement et de 10004 variables :

- smoking_status : variable qualitative (current, former, never) que l'on cherche à prédire.

- never/former/current01 : la transformation en variables binaires de la variable smoking_status qui va nous permettre de construire les modèles.

- cg######## : variables quantitatives (sondes) représentant le taux de méthylation de différents gènes qui seront les variables explicatives.

# Prétraitement

On commence par un pré-traitement qui sera commun aux trois modèles.

On récupère le noms des colonnes correspondants aux sondes (variables exmplicatives).
```{r}
#Nom des sondes
probes = colnames(data_train)[5:10004] 
head(data_train[,probes[1:10]])
```
On trace la densité des 
```{r}
# Description statistique : la densité 
plot(density(as.matrix(data_train[,probes])),main="Densité des valeurs prises par les sondes", xlab="Densité",ylab="Valeurs prises par les variables (methylation)")
```

Sur le graphique, nous pouvons voir apparaitre deux pics : un premier dans l'intervalle $[0;0.2]$ (absence de méthylation) et un second dans l'intervalle $[0;0.7]$ (présence de methylation). 

Regardons la distribution des statuts tabagiques
```{r}
table(data_train$smoking_status)
prop.table(table(data_train$smoking_status))
```
Les 3 statuts sont présents de manière presque équidistribuées. Si on choisissait le modèle nul renvoyant dans tous les cas "former" (le statut le plus courant), on pourrait s'attendre à environ 60% d'erreur.

Pour entrainer nos modèles et pouvoir les tester notamment pour faire de l'hyperparamétrage, nous allons séparer le jeu de donénes `data_train` en deux parties : une partie pour l'entrainement `data_train1` (75%) et une partie pour le test `data_train2` (25%).
```{r}
set.seed(1) # Pour avoir des résultats aléatoire reproductibles.

data_train1 = data_train[sample(1:nrow(data_train), round(nrow(data_train)*.75))
                         ,]
data_train2 = data_train[setdiff(rownames(data_train), rownames(data_train1)),]
```

```{r}
# Comparaison de la séparation de data_train
prop.table(table(data_train1$smoking_status)) 
prop.table(table(data_train2$smoking_status))
```
On remarque que les proportions de chaque groupe (chaque statut tabagique) ne sont pas exactement les mêmes entre data_train1 et data_train2.

Pour les trois modèles, nous n'allons pas utiliser toutes les sondes pour construire nos modèles pour éviter le surajustement et parce que tout simplement certaines sondes n'apportent pas ou peu d'informations. Pour sélectionner les sondes, nous allons construire les modèles linéaires de la forme `lm(sonde~smoking_status)` pour chaque sonde. Cela nous permettra d'étudier la significativité du lien entre le statut tabagique et chaque sonde  à partir de la p-valeur associée au coefficent directeur et ainsi de classer les sondes. 
```{r}
siscreening = function(data_train) {
  probes = colnames(data_train)[5:length(data_train)]  # Noms des sondes
  pval_fisher = c()
  r2 = c()
  for (p in probes) {
    #On crée un modèle linéaire sonde~smoking_status
    m = lm(data_train[,p]~data_train[,"smoking_status"])  
    # On récupère la p-valeur du modèle
    pval_fisher = c(pval_fisher, anova(m)[1,5])  
    # On récupère le r2 associé à ce modèle
    r2 = c(r2, summary(m)$r.squared) 
  }
  names(pval_fisher)  = probes
  names(r2)           = probes
  return(data.frame(pval_fisher=pval_fisher, r2=r2)) 
}
# On mémoise la fonciton pour mettre le résultat en cache.
if (!exists("msiscreening")) {msiscreening = memoise::memoise(siscreening)} 
sis_res = msiscreening(data_train1) # Dataframe résutlat
```

```{r}
# Graphe R2 et p-value
plot(sis_res$r2, -log10(sis_res$pval),
     main="-log10(p-value) des modèles linéaire à une sonde en fonction du R2",
     xlab="R²",ylab="-log10(p-value)")
```
On observe une relation logarithmique entre la p-valeur et le R² : quand la p-valeur devient très petite (-log10(p_val) grand), le R² augmente.

On tri les sondes par ordre croissant de p-valeur.
```{r}
# Tri des sondes en fonction de la p-value
sis_probes = rownames(sis_res)[order(sis_res$pval_fisher)]
head(sis_res[sis_probes,])
# Commentaire : ils ont tous un R2 proche de 0.1, c'est mieux que rien mais c'est pas top.
```

# Méthodes étudiées
Nous allons étudier trois méthodes différentes pour ce datachallenge : un arbre de décision construit à partir de modèles linéaire, un algorithme de random forest et un alorithme de XGBoost. Nous détaillons chacun de ces méthodes dans les parties suivantes.

## 1. Arbre de décision à partir de modèles linéaires
### Idée
L'idée de ce modèle est de construire tout d'abord un premier modèle permettant de séparer les individus en deux groupes selon un des trois statuts tabagiques puis de construire un second modèle entrainé uniquement sur les données des individus des deux autres statuts pour à nouveau séparer les individus restants dans deux groupe selon un des deux status tabagiques restants. Puis, finalement, combiner ces deux modèles pour n'en former qu'un seul : un arbre de décision.

Voici un exemple :
![This is an image](image_arbre_decision.jpg)

### Premier modèle
Nous allons construire pour les trois statuts tabagiques (never, current et former) le premier modèle ayant pour but de prédire si un individu est du statut considéré ou non. Pour chacun de ces modèles, nous allons également réaliser une études des meilleurs hyperparamètres (nombres de sondes et seuil de décision) pour obtenir le meilleur modèle possible. Finalement, nous comparerons les trois modèles sur leur précision (proportion de prédiction correctes).

Commençons avec le statut current, on utilise la variable binaire `current01`, pour construire le modèle.
```{r}
# Fonciton pour créer un modèle linéaire avec les i meilleures sondes
model_current_sis_i = function(data_train, i, screening_func=msiscreening){
  formula = as.formula(paste0(c("current01~1", sis_probes[0:i]), collapse="+")) ; 
  m = glm(formula, data_train, family=binomial(link="logit"))
  return(m)
}

# On regarde le sur apprentissage sur les 50 sondes
iap1 = c()
iap2 = c()
for (i in 0:50) {
  m = model_current_sis_i(data_train1, i)
  pred_train1 = predict.glm(m, data_train1, type="response")
  pred_train2 = predict.glm(m, data_train2, type="response")
  iap1 = c(iap1, sum(ifelse(pred_train1>0.5, 1, 0) != data_train1$current01) / nrow(data_train1))
  iap2 = c(iap2, sum(ifelse(pred_train2>0.5, 1, 0) != data_train2$current01) / nrow(data_train2))
}
plot(iap1, col=4, pch=16, cex=1, main="")
points(iap2, col=2, pch=16, cex=1)
legend("bottomright", c("iap1", "iap2"), col=c(4,2), pch=16, cex=0.8)
i=8
abline(v=i, col=2)
```


```{r}
# On a des sondes qui sont sûrement corrélées et qui apporte la même information : 
# on va faire un step pour choisir les meilleurs sondes à parir du critère d'Aikaike (AIC).

# Fonction de création de modèles step pour CURRENT
stepforward_current = function(data_train, sis_probes, nb_sis_probes=200, trace=0, k=2) {
  m_lo = glm(current01 ~ 1, data=data_train[,c("current01", sis_probes[1:nb_sis_probes])])
  m_sup = glm(current01 ~ ., data=data_train[,c("current01", sis_probes[1:nb_sis_probes])])
  m_fwd = step(m_lo, method="forward", scope=list(upper=m_sup,lower=m_lo), trace=trace, k=k)
  return(m_fwd)
}

# Modèle step obtenu à partir des 90 meilleurs sondes.
step_model_current_90 = stepforward_current(data_train1, sis_probes, nb_sis_probes = 90,trace=0)

# Test de l'accuracy sur le step_model_current_90
predicted_probs <- predict(step_model_current_90, newdata = data_train2, type = "response")
predicted_classes <- ifelse(predicted_probs > 0.5, 1, 0) # On pose le seuil à 0.5
confusion_matrix <- table(Predicted = predicted_classes, Actual = data_train2$current01)
print(confusion_matrix)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(paste("Accuracy:", accuracy))
# Accuracy : 0.80

# Est-ce qu'on peut obtenier un meilleur modèle ? 
# On va jouer sur les hyper-paramètres seuil et nombre de sondes 
# pour la construction du modèle

# Fonction générale de prédiction à partir d'un modèle step + seuil de décision
predict_current <- function(data,step_model, seuil){
  predicted_probs <- predict(step_model, newdata = data, type = "response")
  predicted_classes <- ifelse(predicted_probs > seuil, 1, 0)
  return(predicted_classes)
}

# On crée des modèles pour l'hyperparamétrage.
create_modeles_current <- function(from = 50, to = 200, by = 10) {
  res <- list()
  for (i in seq(from = from, to = to, by = by)) {
    print(paste0(i, "/", to))
    res[[length(res) + 1]] <- stepforward_current(data_train1, sis_probes, nb_sis_probes = i, trace = 0)
  }
  return(res)
}
modeles_current <- create_modeles_current()

# Fonction pour l'hyper-paramétrage de CURRENT
hyperparametrage_current<- function(data, list_modeles_current, list_seuil_current){
  best_accuracy <- 0
  best_seuil_current <- 0
  best_num_model_current <- 1
  
  
  nb <- length(list_modeles_current)*length(list_seuil_current)
  i <- 0
  
  num_model_current <- 0
  for(step_model_current in list_modeles_current){
    num_model_current <- num_model_current +1
    for(seuil_current in list_seuil_current){
      i <- i+1
      if(i%%10 == 0){
        print(paste0(i,"/",nb))
      }
      confusion_matrix <- table(Predicted = predict_current(data,step_model_current,seuil_current), Actual = data$current01)
      accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
      if(accuracy > best_accuracy){
            best_accuracy <- accuracy
            best_num_model_current <- num_model_current
            best_seuil_current <- seuil_current
      }
    }
  }
  return(c(best_accuracy,best_num_model_current,best_seuil_current))
}

hyperparametrage_current(data_train2,modeles_current,list(0.4,0.425,0.45,0.475,0.5,0.525,0.55,0.575,0.6))
# Res :
# Accuracy : 0.82857
# Modèle n*15 -> 190 sondes
# Seuil : 0.575
```

```{r}
# NEVER
model_never_sis_i = function(data_train, i, screening_func=msiscreening){
  print(paste0("model sis ", i))
  sis_res = screening_func(data_train)  
  sis_probes = rownames(sis_res)[order(sis_res$pval_fisher)]
  formula = as.formula(paste0(c("never01~1", sis_probes[0:i]), collapse="+")) ; 
  m = glm(formula, data_train, family=binomial(link="logit"))
  return(m)
}
# On regarde le sur apprentissage sur les 50 sondes
iap1 = c()
iap2 = c()
for (i in 0:50) {
  m = model_never_sis_i(data_train1, i)
  pred_train1 = predict.glm(m, data_train1, type="response")
  pred_train2 = predict.glm(m, data_train2, type="response")
  iap1 = c(iap1, sum(ifelse(pred_train1>0.5, 1, 0) != data_train1$never01) / nrow(data_train1))
  iap2 = c(iap2, sum(ifelse(pred_train2>0.5, 1, 0) != data_train2$never01) / nrow(data_train2))
}
plot(iap1, col=4, pch=16, cex=1)
points(iap2, col=2, pch=16, cex=1)
legend("bottomright", c("iap1", "iap2"), col=c(4,2), pch=16, cex=0.8)
i=8
abline(v=i, col=2)

# On effectue un step 
stepforward_never = function(data_train, sis_probes, nb_sis_probes=200, trace=0, k=2) {
  m_lo = glm(never01 ~ 1, data=data_train[,c("never01", sis_probes[1:nb_sis_probes])])
  m_sup = glm(never01 ~ ., data=data_train[,c("never01", sis_probes[1:nb_sis_probes])])
  m_fwd = step(m_lo, method="forward", scope=list(upper=m_sup,lower=m_lo), trace=trace, k=k)
  # print(m_fwd$call)
  return(m_fwd)
}

# Exemple avec 90 sondes
step_model_never_90 = stepforward_never(data_train1, sis_probes, nb_sis_probes = 90,trace=0)

# On regarde les résultats sur data_train2
predicted_probs <- predict(step_model_never_90, newdata = data_train2, type = "response")
predicted_classes <- ifelse(predicted_probs > 0.55, 1, 0)
confusion_matrix <- table(Predicted = predicted_classes, Actual = data_train2$never01)
print(confusion_matrix)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(paste("Accuracy:", accuracy))
# Accuracy : 0.69

# Fonction générale
predict_never <- function(data,step_model, seuil){
  predicted_probs <- predict(step_model, newdata = data, type = "response")
  predicted_classes <- ifelse(predicted_probs > seuil, 1, 0)
  return(predicted_classes)
}

# On crée des modèles pour l'hyperparamétrage.
create_modeles_never <- function(from = 50, to = 200, by = 10) {
  res <- list()
  for (i in seq(from = from, to = to, by = by)) {
    print(paste0(i, "/", to))
    res[[length(res) + 1]] <- stepforward_never(data_train1, sis_probes, nb_sis_probes = i, trace = 0)
  }
  return(res)
}
modeles_never <- create_modeles_never()

# Fonction pour l'hyper-paramétrage de never
hyperparametrage_never<- function(data, list_modeles_never, list_seuil_never){
  best_accuracy <- 0
  best_seuil_never <- 0
  best_num_model_never <- 1
  
  
  nb <- length(list_modeles_never)*length(list_seuil_never)
  i <- 0
  
  num_model_never <- 0
  for(step_model_never in list_modeles_never){
    num_model_never <- num_model_never +1
    for(seuil_never in list_seuil_never){
      i <- i+1
      if(i%%10 == 0){
        print(paste0(i,"/",nb))
      }
      confusion_matrix <- table(Predicted = predict_never(data,step_model_never,seuil_never), Actual = data$never01)
      accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
      if(accuracy > best_accuracy){
        best_accuracy <- accuracy
        best_num_model_never <- num_model_never
        best_seuil_never <- seuil_never
      }
    }
  }
  return(c(best_accuracy,best_num_model_never,best_seuil_never))
}

hyperparametrage_never(data_train2,modeles_never,list(0.4,0.425,0.45,0.475,0.5,0.525,0.55,0.575,0.6))

# Res
# Accuracy : 0.724
# Modèles n*3 -> 70 sondes
# Seuil = 0.425

```

```{r}

# FORMER
model_former_sis_i = function(data_train, i, screening_func=msiscreening){
  print(paste0("model sis ", i))
  sis_res = screening_func(data_train)  
  sis_probes = rownames(sis_res)[order(sis_res$pval_fisher)]
  formula = as.formula(paste0(c("former01~1", sis_probes[0:i]), collapse="+")) ; 
  m = glm(formula, data_train, family=binomial(link="logit"))
  return(m)
}
# On regarde le sur apprentissage sur les 50 sondes
iap1 = c()
iap2 = c()
for (i in 0:50) {
  m = model_former_sis_i(data_train1, i)
  pred_train1 = predict.glm(m, data_train1, type="response")
  pred_train2 = predict.glm(m, data_train2, type="response")
  iap1 = c(iap1, sum(ifelse(pred_train1>0.5, 1, 0) != data_train1$former01) / nrow(data_train1))
  iap2 = c(iap2, sum(ifelse(pred_train2>0.5, 1, 0) != data_train2$former01) / nrow(data_train2))
}
plot(iap1, col=4, pch=16, cex=1)
points(iap2, col=2, pch=16, cex=1)
legend("bottomright", c("iap1", "iap2"), col=c(4,2), pch=16, cex=0.8)
i=8
abline(v=i, col=2)

# On effectue un step 
stepforward_former = function(data_train, sis_probes, nb_sis_probes=200, trace=0, k=2) {
  m_lo = glm(former01 ~ 1, data=data_train[,c("former01", sis_probes[1:nb_sis_probes])])
  m_sup = glm(former01 ~ ., data=data_train[,c("former01", sis_probes[1:nb_sis_probes])])
  m_fwd = step(m_lo, method="forward", scope=list(upper=m_sup,lower=m_lo), trace=trace, k=k)
  # print(m_fwd$call)
  return(m_fwd)
}

step_model_former_90 = stepforward_former(data_train1, sis_probes, nb_sis_probes = 90,trace=0)
# On regarde les résultats sur data_train2
predicted_probs <- predict(step_model_former_90, newdata = data_train2, type = "response")
predicted_classes <- ifelse(predicted_probs > 0.55, 1, 0)
confusion_matrix <- table(Predicted = predicted_classes, Actual = data_train2$former01)
print(confusion_matrix)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(paste("Accuracy:", accuracy))

# Fonction générale
predict_former <- function(data,step_model, seuil){
  predicted_probs <- predict(step_model, newdata = data, type = "response")
  predicted_classes <- ifelse(predicted_probs > seuil, 1, 0)
  return(predicted_classes)
}


# On crée des modèles pour l'hyperparamétrage.
create_modeles_former <- function(from = 50, to = 200, by = 10) {
  res <- list()
  for (i in seq(from = from, to = to, by = by)) {
    print(paste0(i, "/", to))
    res[[length(res) + 1]] <- stepforward_former(data_train1, sis_probes, nb_sis_probes = i, trace = 0)
  }
  return(res)
}
modeles_former <- create_modeles_former()

# Fonction pour l'hyper-paramétrage de former
hyperparametrage_former<- function(data, list_modeles_former, list_seuil_former){
  best_accuracy <- 0
  best_seuil_former <- 0
  best_num_model_former <- 1
  
  
  nb <- length(list_modeles_former)*length(list_seuil_former)
  i <- 0
  
  num_model_former <- 0
  for(step_model_former in list_modeles_former){
    num_model_former <- num_model_former +1
    for(seuil_former in list_seuil_former){
      i <- i+1
      if(i%%10 == 0){
        print(paste0(i,"/",nb))
      }
      confusion_matrix <- table(Predicted = predict_former(data,step_model_former,seuil_former), Actual = data$former01)
      accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
      if(accuracy > best_accuracy){
        best_accuracy <- accuracy
        best_num_model_former <- num_model_former
        best_seuil_former <- seuil_former
      }
    }
  }
  return(c(best_accuracy,best_num_model_former,best_seuil_former))
}

hyperparametrage_former(data_train2,modeles_former,list(0.4,0.425,0.45,0.475,0.5,0.525,0.55,0.575,0.6))

# Res : 
# Accuracy : 0.7142
# Modèle n*10 -> 140 sondes
# Seuil : 0.575
```

Comme le modèle Current est celui avec la meilleure précision, on va partir de ce statut comme première partie de l'arbre. Nous allons maintenant construire deux modèles (former et never) uniquement entrainé sur les données des individus n'étant pas actuellement current (puisqu'ils sont censés être labelisé current par le modèle current).

### Deuxième modèle
```{r}

# On va repartir de data_train1 et data_train2 mais en enlevant les gens qui sont current.
data_train1_notcurrent <- data_train1[data_train1$current01!=1,]
data_train2_notcurrent <- data_train2[data_train2$current01!=1,]
dim(data_train1)
dim(data_train1_notcurrent)
dim(data_train2)
dim(data_train2_notcurrent)
```

```{r}
# NOT CURRENT - NEVER
# NEVER
model_never_sis_i = function(data_train, i, screening_func=msiscreening){
  print(paste0("model sis ", i))
  sis_res = screening_func(data_train)
  sis_probes = rownames(sis_res)[order(sis_res$pval_fisher)]
  formula = as.formula(paste0(c("never01~1", sis_probes[0:i]), collapse="+")) ; 
  m = glm(formula, data_train, family=binomial(link="logit"))
  return(m)
}

# On effectue un step 
stepforward_never = function(data_train, sis_probes, nb_sis_probes=200, trace=0, k=2) {
  m_lo = glm(never01 ~ 1, data=data_train[,c("never01", sis_probes[1:nb_sis_probes])])
  m_sup = glm(never01 ~ ., data=data_train[,c("never01", sis_probes[1:nb_sis_probes])])
  m_fwd = step(m_lo, method="forward", scope=list(upper=m_sup,lower=m_lo), trace=trace, k=k)
  # print(m_fwd$call)
  return(m_fwd)
}

# Exemple avec 90 sondes
step_model_notcurrent_never_90 = stepforward_never(data_train1_notcurrent, sis_probes, nb_sis_probes = 90,trace=0)

# On regarde les résultats sur data_train2
predicted_probs <- predict(step_model_notcurrent_never_90, newdata = data_train2_notcurrent, type = "response")
predicted_classes <- ifelse(predicted_probs > 0.5, 1, 0)
confusion_matrix <- table(Predicted = predicted_classes, Actual = data_train2_notcurrent$never01)
print(confusion_matrix)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(paste("Accuracy:", accuracy))
# Accuracy : 0.5217

# Fonction générale
predict_notcurrent_never <- function(data,step_model, seuil){
  predicted_probs <- predict(step_model, newdata = data, type = "response")
  predicted_classes <- ifelse(predicted_probs > seuil, 1, 0)
  return(predicted_classes)
}

# On crée des modèles pour l'hyperparamétrage.
create_modeles_notcurrent_never <- function(from = 50, to = 200, by = 10) {
  res <- list()
  for (i in seq(from = from, to = to, by = by)) {
    print(paste0(i, "/", to))
    res[[length(res) + 1]] <- stepforward_never(data_train1_notcurrent, sis_probes, nb_sis_probes = i, trace = 0)
  }
  return(res)
}
modeles_notcurrent_never <- create_modeles_notcurrent_never()

# Fonction pour l'hyper-paramétrage de never
hyperparametrage_notcurrent_never<- function(data, list_modeles_never, list_seuil_never){
  best_accuracy <- 0
  best_seuil_never <- 0
  best_num_model_never <- 1
  
  
  nb <- length(list_modeles_never)*length(list_seuil_never)
  i <- 0
  
  num_model_never <- 0
  for(step_model_never in list_modeles_never){
    num_model_never <- num_model_never +1
    for(seuil_never in list_seuil_never){
      i <- i+1
      if(i%%10 == 0){
        print(paste0(i,"/",nb))
      }
      confusion_matrix <- table(Predicted = predict_never(data,step_model_never,seuil_never), Actual = data$never01)
      accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
      if(accuracy > best_accuracy){
        best_accuracy <- accuracy
        best_num_model_never <- num_model_never
        best_seuil_never <- seuil_never
      }
    }
  }
  return(c(best_accuracy,best_num_model_never,best_seuil_never))
}

hyperparametrage_notcurrent_never(data_train2_notcurrent,modeles_notcurrent_never,list(0.4,0.425,0.45,0.475,0.5,0.525,0.55,0.575,0.6))
# Res
# Accuracy : 0.5652
# Modèle n*3 -> 70 sondes
# Seuil : 0.425

```

```{r}
# NOT CURRENT - former
# former
model_former_sis_i = function(data_train, i, screening_func=msiscreening){
  print(paste0("model sis ", i))
  sis_res = screening_func(data_train)
  sis_probes = rownames(sis_res)[order(sis_res$pval_fisher)]
  formula = as.formula(paste0(c("former01~1", sis_probes[0:i]), collapse="+")) ; 
  m = glm(formula, data_train, family=binomial(link="logit"))
  return(m)
}

# On effectue un step 
stepforward_former = function(data_train, sis_probes, nb_sis_probes=200, trace=0, k=2) {
  m_lo = glm(former01 ~ 1, data=data_train[,c("former01", sis_probes[1:nb_sis_probes])])
  m_sup = glm(former01 ~ ., data=data_train[,c("former01", sis_probes[1:nb_sis_probes])])
  m_fwd = step(m_lo, method="forward", scope=list(upper=m_sup,lower=m_lo), trace=trace, k=k)
  # print(m_fwd$call)
  return(m_fwd)
}

# Exemple avec 90 sondes
step_model_notcurrent_former_90 = stepforward_former(data_train1_notcurrent, sis_probes, nb_sis_probes = 90,trace=0)

# On regarde les résultats sur data_train2
predicted_probs <- predict(step_model_notcurrent_former_90, newdata = data_train2_notcurrent, type = "response")
predicted_classes <- ifelse(predicted_probs > 0.5, 1, 0)
confusion_matrix <- table(Predicted = predicted_classes, Actual = data_train2_notcurrent$former01)
print(confusion_matrix)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(paste("Accuracy:", accuracy))
# Accuracy : 0.5217

# Fonction générale
predict_notcurrent_former <- function(data,step_model, seuil){
  predicted_probs <- predict(step_model, newdata = data, type = "response")
  predicted_classes <- ifelse(predicted_probs > seuil, 1, 0)
  return(predicted_classes)
}

# On crée des modèles pour l'hyperparamétrage.
create_modeles_notcurrent_former <- function(from = 50, to = 200, by = 10) {
  res <- list()
  for (i in seq(from = from, to = to, by = by)) {
    print(paste0(i, "/", to))
    res[[length(res) + 1]] <- stepforward_former(data_train1_notcurrent, sis_probes, nb_sis_probes = i, trace = 0)
  }
  return(res)
}
modeles_notcurrent_former <- create_modeles_notcurrent_former()

# Fonction pour l'hyper-paramétrage de former
hyperparametrage_notcurrent_former<- function(data, list_modeles_former, list_seuil_former){
  best_accuracy <- 0
  best_seuil_former <- 0
  best_num_model_former <- 1
  
  
  nb <- length(list_modeles_former)*length(list_seuil_former)
  i <- 0
  
  num_model_former <- 0
  for(step_model_former in list_modeles_former){
    num_model_former <- num_model_former +1
    for(seuil_former in list_seuil_former){
      i <- i+1
      if(i%%10 == 0){
        print(paste0(i,"/",nb))
      }
      confusion_matrix <- table(Predicted = predict_former(data,step_model_former,seuil_former), Actual = data$former01)
      accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
      if(accuracy > best_accuracy){
        best_accuracy <- accuracy
        best_num_model_former <- num_model_former
        best_seuil_former <- seuil_former
      }
    }
  }
  return(c(best_accuracy,best_num_model_former,best_seuil_former))
}

hyperparametrage_notcurrent_former(data_train2_notcurrent,modeles_notcurrent_former,list(0.4,0.425,0.45,0.475,0.5,0.525,0.55,0.575,0.6))
# Res
# Accuracy : 0.5652
# Modèle n*3 -> 70 sondes
# Seuil : 0.525
```
Les deux ont les mêmes résultats donc arbitrairement on choisi never

### Combinaison des deux modèles
```{r}
predict_current_never<- function(data,step_model_current,seuil_current,step_model_never,seuil_never){
  
  # Étape 1 : Initialisation du vecteur de prédictions
  n <- nrow(data)
  predictions <- rep(NA, times=n)
  
  # Étape 2 : Prédictions pour "current"
  is_current <- predict_current(data,step_model_current,seuil_current) == 1
  predictions[is_current] <- "current"
  
  # Étape 3 : Prédictions pour "never" parmi les non-classés
  remaining <- is.na(predictions)
  is_never <- predict_notcurrent_never(data[remaining, ],step_model_never,seuil_never) == 1
  predictions[which(remaining)[is_never]] <- "never"
  
  # Étape 4 : Tout le reste est "former"
  predictions[is.na(predictions)] <- "former"
  
  return(predictions)
}

model_current_final <- stepforward_current(data_train1, sis_probes, nb_sis_probes = 190,trace=0)

model_never_final <- stepforward_never(data_train1_notcurrent, sis_probes, nb_sis_probes = 70,trace=0)

```

```{r}
# Essai sur data_train2
predicted <- predict_current_never(data_train2, model_current_final,0.575,model_never_final,0.425)
confusion_matrix <- table(Predicted = predicted, Actual = data_train2$smoking_status)
print(confusion_matrix)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(paste("Accuracy:", accuracy))
```


## 2. Random forest

## 3. XGBoost

# Résultats

## 1. Arbre de décision à partir de modèles linéaires
### Résultats sur data_train2

### Résultats sur data_test
La soumission correspondante sur CodaBench est la numéro 481 du 15 décembre 2024 publiée par l'utilisateur malnoe.  Le résultat obtenu est de 0.46.

## 2. Random forest
### Résultats sur data_train2
### Résultats sur data_test
Mettre numéro de la soumission sur codabench.

## 3. XGBoost
### Résultats sur data_train2
### Résultats sur data_test
Mettre numéro de la soumission sur codabench.

# Discussion
## Commentaires des résultats
## Proposer des faits pour détailler les résultats (cohérence ou différences)

